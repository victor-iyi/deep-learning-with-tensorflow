{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2-Layer Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "save_dir = '../saved/convnet/2-layers'\n",
    "data_dir = '../datasets/MNIST'\n",
    "saved_data = os.path.join(save_dir, f'data/{os.path.basename(data_dir)}.pkl')\n",
    "\n",
    "if not os.path.isfile(saved_data):\n",
    "    start = dt.now()\n",
    "    data = input_data.read_data_sets(data_dir, one_hot=True)\n",
    "    print(f'Took {dt.now() - start}')\n",
    "    if not os.path.exists(os.path.dirname(saved_data)):\n",
    "        os.makedirs(os.path.dirname(saved_data))\n",
    "    pickle.dump(file=open(saved_data, 'wb'), obj=data)\n",
    "    \n",
    "    print('\\nCached data for future use.')\n",
    "else:\n",
    "    start = dt.now()\n",
    "    data = pickle.load(file=open(saved_data, 'rb'))\n",
    "    print('Loaded cached data.')\n",
    "    print(f'Took {dt.now() - start}')\n",
    "\n",
    "# free memory\n",
    "del start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Training set    = {:,}'.format(len(data.train.labels)))\n",
    "print('Testing set     = {:,}'.format(len(data.test.labels)))\n",
    "print('Validation set  =  {:,}'.format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data dimension\n",
    "image_size = 28\n",
    "image_channel = 1\n",
    "image_shape = (image_size, image_size, image_channel)\n",
    "image_shape_flat = image_size * image_size\n",
    "num_classes = 10\n",
    "\n",
    "# Network\n",
    "filter_size = 5\n",
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "fc_size = 256\n",
    "dropout = 0.8\n",
    "\n",
    "# Training\n",
    "train_batch = 100\n",
    "test_batch = 50\n",
    "val_batch = 25\n",
    "learning_rate = 1e-1\n",
    "n_iters = 0  # Total number of completed optimization iterations\n",
    "save_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### `weights` and `biases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def weight(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.5, mean=0)\n",
    "    return tf.Variable(initial, name='weight')\n",
    "\n",
    "def bias(shape):\n",
    "    initial = tf.zeros(shape=[shape])\n",
    "    return tf.Variable(initial, name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### `convolution` and `pooling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(X, W):\n",
    "    return tf.nn.conv2d(X, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool(X):\n",
    "    return tf.nn.max_pool(X, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### `flatten` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def flatten(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = np.array(layer_shape[1:4], dtype=int).prod()\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Building the Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Placeholder variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, image_shape_flat])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X_image = tf.reshape(X, [-1, image_size, image_size, image_channel])\n",
    "y_true = tf.argmax(y, axis=1)\n",
    "X_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building the `convnet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Input Layer »» Hidden Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_hidden1 = weight(shape=[filter_size, filter_size, image_channel, filter_1])\n",
    "b_hidden1 = bias(shape=filter_1)\n",
    "hidden1 = tf.nn.relu(conv2d(X_image, W_hidden1) + b_hidden1)\n",
    "hidden1 = max_pool(hidden1)\n",
    "hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Hidden Layer 1 »» Hidden Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_hidden2 = weight(shape=[filter_size, filter_size, filter_1, filter_2])\n",
    "b_hidden2 = bias(shape=filter_2)\n",
    "hidden2 = tf.nn.relu(conv2d(hidden1, W_hidden2) + b_hidden2)\n",
    "hidden2 = max_pool(hidden2)\n",
    "hidden2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Flatten Hidden Layer 2 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden2_flat, num_features = flatten(hidden2)\n",
    "hidden2_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### HIdden Layer 2 »» Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_fc = weight(shape=[num_features, fc_size])\n",
    "b_fc = bias(shape=fc_size)\n",
    "fc_layer = tf.nn.relu(tf.matmul(hidden2_flat, W_fc) + b_fc)\n",
    "fc_drop = tf.nn.dropout(fc_layer, keep_prob=keep_prob)\n",
    "fc_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Fully connected Layer »» Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_out = weight(shape=[fc_size, num_classes])\n",
    "b_out = bias(shape=num_classes)\n",
    "logits = tf.matmul(fc_layer, W_out) + b_out\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "y_pred_true = tf.argmax(y_pred, axis=1)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "cost = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(y_true, y_pred_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Running the Computional Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### tensorflow's `Session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard logging\n",
    "tensorboard_dir = os.path.join(save_dir, 'tensorboard')\n",
    "logdir = os.path.join(tensorboard_dir, 'log')\n",
    "# Pre-trained model\n",
    "model_dir = os.path.join(save_dir, 'models')\n",
    "model_file = os.path.join(model_dir, 'model.ckpt')\n",
    "\n",
    "# Summary\n",
    "tf.summary.scalar('cost', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# writer and saver\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(logdir=logdir, graph=sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if tf.gfile.Exists(model_dir):\n",
    "    try:\n",
    "        print('INFO: Attempting to restore last checkpoint.')\n",
    "        last_ckpt = tf.train.latest_checkpoint(model_dir)\n",
    "        saver.restore(sess=sess, save_path=last_ckpt)\n",
    "        print(f'SUCCESS: Checkpoint restored @ {last_ckpt}')\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f'ERR: Could not load checkpoint. {e}')\n",
    "        sys.stderr.flush()\n",
    "else:\n",
    "    tf.gfile.MakeDirs(model_dir)\n",
    "    print(f'INFO: Checkpoint folder created - {model_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Perform Optimzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(iterations=1000):\n",
    "    global n_iters\n",
    "    start = dt.now()\n",
    "    for _ in range(iterations):\n",
    "        n_iters += 1\n",
    "        X_batch, y_batch = data.train.next_batch(train_batch)\n",
    "        feed_dict = {X: X_batch, y: y_batch, keep_prob: dropout}\n",
    "        _, i_global = sess.run([train_step, global_step], feed_dict=feed_dict)\n",
    "        # Save checkpoint and summarize tensorboard\n",
    "        if n_iters % save_interval == 0:\n",
    "            summary = sess.run(merged, feed_dict=feed_dict)\n",
    "            writer.add_summary(summary, global_step=i_global)\n",
    "            saver.save(sess=sess, save_path=model_file, global_step=global_step)\n",
    "        # Log progress\n",
    "        sys.stdout.write(f'\\rIter: {n_iters:,}\\tGlobal step: {i_global:,}'\n",
    "                         f'\\tTime taken: {dt.now() - start}')\n",
    "        sys.stdout.flush()\n",
    "    print(f\"\\n{80*'='}\")\n",
    "    print('\\tCompleted {n_iters:,} iterations.')\n",
    "    print(80*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def score(test=True, validation=False, use_batch=True):\n",
    "    print(80*'=')\n",
    "    print('Accuracy after {:,} iterations'.format(n_iters))\n",
    "    feed_dict = {}\n",
    "    if test:\n",
    "        if use_batch:\n",
    "            X_batch, y_batch = data.test.next_batch(test_batch)\n",
    "            feed_dict = {X: X_batch, y: y_batch, keep_prob:dropout}\n",
    "        else:\n",
    "            feed_dict = {X: data.test.images, y: data.test.labels, keep_prob:dropout}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        print('Accuracy on test set: {:.02%}'.format(acc))\n",
    "    if validation:\n",
    "        if use_batch:\n",
    "            X_batch, y_batch = data.validation.next_batch(val_batch)\n",
    "            feed_dict = {X: X_batch, y: y_batch, keep_prob:dropout}\n",
    "        else:\n",
    "            feed_dict = {X: data.validation.images, y: data.validation.labels, keep_prob:dropout}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        print('Accuracy on validation set: {:.02%}'.format(acc))\n",
    "    print(80*'=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training the Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train(iterations=10)\n",
    "score(test=True, use_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(iterations=90)\n",
    "score(test=True, use_batch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train(iterations=900)\n",
    "score(test=True, validation=True, use_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train(iterations=9000)\n",
    "score(test=True, validation=True, use_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clear saved mnist `data`\n",
    "shutil.rmtree(os.path.dirname(saved_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
